package main

import (
	"encoding/json"
	"fmt"
	"log"
	"strings"
	"time"

	mc "github.com/kydenul/markdown-chunker"
)

func main() {
	fmt.Println("=== ç»¼åˆåŠŸèƒ½æ¼”ç¤ºç¤ºä¾‹ ===")

	// åˆ›å»ºä¸€ä¸ªå¤æ‚çš„æµ‹è¯•æ–‡æ¡£
	complexMarkdown := createComplexTestDocument()

	// æ¼”ç¤ºå„ç§åŠŸèƒ½
	demonstrateBasicUsage(complexMarkdown)
	demonstrateChunkingStrategies(complexMarkdown) // NEW: Strategy demonstration
	demonstrateAdvancedFeatures(complexMarkdown)
	demonstrateErrorHandlingAndRecovery(complexMarkdown)
	demonstratePerformanceMonitoring(complexMarkdown)
	demonstrateLoggingFeatures(complexMarkdown)
	demonstrateMetadataExtraction(complexMarkdown)
	demonstrateContentAnalysis(complexMarkdown)
}

// createComplexTestDocument åˆ›å»ºå¤æ‚çš„æµ‹è¯•æ–‡æ¡£
func createComplexTestDocument() string {
	return `# ç»¼åˆåŠŸèƒ½æµ‹è¯•æ–‡æ¡£

è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯• Markdown Chunker æ‰€æœ‰åŠŸèƒ½çš„ç»¼åˆæ–‡æ¡£ã€‚

## é“¾æ¥å’Œå›¾ç‰‡æµ‹è¯•

### å„ç§ç±»å‹çš„é“¾æ¥

- å¤–éƒ¨é“¾æ¥: [Google](https://www.google.com)
- å†…éƒ¨é“¾æ¥: [å…³äºé¡µé¢](/about)
- é”šç‚¹é“¾æ¥: [è·³è½¬åˆ°ç»“è®º](#conclusion)
- é‚®ä»¶é“¾æ¥: [è”ç³»æˆ‘ä»¬](mailto:contact@example.com)
- è‡ªåŠ¨é“¾æ¥: https://github.com/example/repo

### å›¾ç‰‡æµ‹è¯•

![ä¸»å›¾ç‰‡](https://example.com/main.jpg "ä¸»å›¾ç‰‡æ ‡é¢˜")

![æœ¬åœ°å›¾ç‰‡](./images/local.png)

![æ— æ ‡é¢˜å›¾ç‰‡](image-without-title.gif)

## ä»£ç å¤æ‚åº¦æµ‹è¯•

### ç®€å•ä»£ç 

` + "```python" + `
def simple_function():
    return "Hello, World!"
` + "```" + `

### å¤æ‚ä»£ç 

` + "```javascript" + `
function complexAlgorithm(data) {
    let result = [];
    
    for (let i = 0; i < data.length; i++) {
        if (data[i] > 0) {
            for (let j = 0; j < data[i]; j++) {
                if (j % 2 === 0) {
                    result.push(j * 2);
                } else {
                    try {
                        result.push(processOddNumber(j));
                    } catch (error) {
                        console.error("Error processing:", error);
                        continue;
                    }
                }
            }
        } else if (data[i] < 0) {
            while (Math.abs(data[i]) > 0) {
                result.push(Math.abs(data[i]));
                data[i]++;
            }
        } else {
            switch (data[i]) {
                case 0:
                    result.push(0);
                    break;
                default:
                    result.push(null);
            }
        }
    }
    
    return result.filter(item => item !== null);
}

function processOddNumber(num) {
    if (num < 0) throw new Error("Negative number");
    return num * 3;
}
` + "```" + `

### Go ä»£ç ç¤ºä¾‹

` + "```go" + `
package main

import (
    "fmt"
    "sync"
)

func main() {
    var wg sync.WaitGroup
    ch := make(chan int, 10)
    
    // å¯åŠ¨å·¥ä½œåç¨‹
    for i := 0; i < 3; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            for num := range ch {
                if num%2 == 0 {
                    fmt.Printf("Worker %d: Even %d\n", id, num)
                } else {
                    fmt.Printf("Worker %d: Odd %d\n", id, num)
                }
            }
        }(i)
    }
    
    // å‘é€æ•°æ®
    for i := 0; i < 20; i++ {
        ch <- i
    }
    close(ch)
    
    wg.Wait()
}
` + "```" + `

## è¡¨æ ¼æµ‹è¯•

### æ ‡å‡†è¡¨æ ¼

| äº§å“åç§° | ä»·æ ¼ | åº“å­˜çŠ¶æ€ | é“¾æ¥ |
|----------|------|----------|------|
| ç¬”è®°æœ¬ç”µè„‘ | Â¥5999 | æœ‰åº“å­˜ | [æŸ¥çœ‹è¯¦æƒ…](https://shop.com/laptop) |
| æ™ºèƒ½æ‰‹æœº | Â¥2999 | ç¼ºè´§ | [æŸ¥çœ‹è¯¦æƒ…](https://shop.com/phone) |
| å¹³æ¿ç”µè„‘ | Â¥1999 | æœ‰åº“å­˜ | [æŸ¥çœ‹è¯¦æƒ…](https://shop.com/tablet) |

### å¸¦å¯¹é½çš„è¡¨æ ¼

| å·¦å¯¹é½ | å±…ä¸­å¯¹é½ | å³å¯¹é½ | æ•°å€¼ |
|:-------|:--------:|-------:|-----:|
| æ–‡æœ¬A | æ–‡æœ¬B | æ–‡æœ¬C | 123.45 |
| é•¿æ–‡æœ¬å†…å®¹ | çŸ­æ–‡æœ¬ | æ–‡æœ¬ | 67.89 |
| A | ä¸­ç­‰é•¿åº¦æ–‡æœ¬ | å¾ˆé•¿çš„æ–‡æœ¬å†…å®¹ | 0.12 |

### æ ¼å¼ä¸è§„èŒƒçš„è¡¨æ ¼

| å§“å | å¹´é¾„ | åŸå¸‚ |
|------|------|------|
| å¼ ä¸‰ | 25 | åŒ—äº¬ | å¤šä½™åˆ— |
| æå›› | 30 |  |
| ç‹äº” |  | ä¸Šæµ· |

## åˆ—è¡¨æµ‹è¯•

### æœ‰åºåˆ—è¡¨

1. ç¬¬ä¸€é¡¹
2. ç¬¬äºŒé¡¹
   1. å­é¡¹ 2.1
   2. å­é¡¹ 2.2
      1. æ·±å±‚å­é¡¹ 2.2.1
3. ç¬¬ä¸‰é¡¹

### æ— åºåˆ—è¡¨

- é¡¹ç›® A
- é¡¹ç›® B
  - å­é¡¹ç›® B.1
  - å­é¡¹ç›® B.2
    - æ·±å±‚å­é¡¹ç›® B.2.1
- é¡¹ç›® C

### æ··åˆåˆ—è¡¨

1. æœ‰åºé¡¹ç›® 1
   - æ— åºå­é¡¹ç›®
   - å¦ä¸€ä¸ªæ— åºå­é¡¹ç›®
2. æœ‰åºé¡¹ç›® 2
   1. æœ‰åºå­é¡¹ç›®
   2. å¦ä¸€ä¸ªæœ‰åºå­é¡¹ç›®

## å¼•ç”¨å—æµ‹è¯•

> è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å¼•ç”¨å—ã€‚

> è¿™æ˜¯ä¸€ä¸ªå¤šè¡Œå¼•ç”¨å—ã€‚
> å®ƒåŒ…å«å¤šè¡Œå†…å®¹ï¼Œ
> ç”¨äºæµ‹è¯•å¼•ç”¨å—çš„å¤„ç†èƒ½åŠ›ã€‚

> è¿™æ˜¯ä¸€ä¸ªåŒ…å«é“¾æ¥çš„å¼•ç”¨å—ï¼š[é“¾æ¥](https://example.com)
> 
> è¿˜åŒ…å«**ç²—ä½“**å’Œ*æ–œä½“*æ–‡æœ¬ã€‚

### åµŒå¥—å¼•ç”¨

> è¿™æ˜¯å¤–å±‚å¼•ç”¨ã€‚
> 
> > è¿™æ˜¯åµŒå¥—å¼•ç”¨ã€‚
> > 
> > > è¿™æ˜¯æ·±å±‚åµŒå¥—å¼•ç”¨ã€‚
> 
> å›åˆ°å¤–å±‚å¼•ç”¨ã€‚

## ç‰¹æ®Šå†…å®¹æµ‹è¯•

### åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å†…å®¹

è¿™ä¸ªæ®µè½åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼š` + "`ä»£ç `" + `ã€**ç²—ä½“**ã€*æ–œä½“*ã€~~åˆ é™¤çº¿~~ã€‚

è¿˜æœ‰ä¸€äº› Unicode å­—ç¬¦ï¼šğŸš€ ğŸ“ ğŸ’» ğŸ¯

### é•¿æ®µè½æµ‹è¯•

` + strings.Repeat("è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•é•¿æ®µè½å¤„ç†èƒ½åŠ›çš„é‡å¤å†…å®¹ã€‚", 20) + `

---

## ç»“è®º {#conclusion}

è¿™ä¸ªæ–‡æ¡£åŒ…å«äº†å„ç§ Markdown å…ƒç´ ï¼Œç”¨äºå…¨é¢æµ‹è¯•åˆ†å—å™¨çš„åŠŸèƒ½ï¼š

- âœ… æ ‡é¢˜å±‚æ¬¡ç»“æ„
- âœ… æ®µè½å’Œæ–‡æœ¬æ ¼å¼
- âœ… ä»£ç å—ï¼ˆå¤šç§è¯­è¨€ï¼‰
- âœ… è¡¨æ ¼ï¼ˆæ ‡å‡†å’Œä¸è§„èŒƒï¼‰
- âœ… åˆ—è¡¨ï¼ˆæœ‰åºã€æ— åºã€åµŒå¥—ï¼‰
- âœ… å¼•ç”¨å—ï¼ˆç®€å•å’ŒåµŒå¥—ï¼‰
- âœ… é“¾æ¥ï¼ˆå„ç§ç±»å‹ï¼‰
- âœ… å›¾ç‰‡
- âœ… åˆ†éš”çº¿
- âœ… ç‰¹æ®Šå­—ç¬¦å’Œ Unicode

*æ–‡æ¡£ç»“æŸ*`
}

// demonstrateBasicUsage æ¼”ç¤ºåŸºæœ¬ç”¨æ³•
func demonstrateBasicUsage(markdown string) {
	fmt.Println("\n=== 1. åŸºæœ¬ç”¨æ³•æ¼”ç¤º ===")

	chunker := mc.NewMarkdownChunker()
	chunks, err := chunker.ChunkDocument([]byte(markdown))
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("æ–‡æ¡£ç»Ÿè®¡:\n")
	fmt.Printf("  åŸå§‹æ–‡æ¡£å¤§å°: %d å­—èŠ‚\n", len(markdown))
	fmt.Printf("  ç”Ÿæˆå—æ•°é‡: %d\n", len(chunks))

	// ç»Ÿè®¡å„ç±»å‹å—
	typeCount := make(map[string]int)
	for _, chunk := range chunks {
		typeCount[chunk.Type]++
	}

	fmt.Printf("  å—ç±»å‹åˆ†å¸ƒ:\n")
	for chunkType, count := range typeCount {
		fmt.Printf("    %s: %d\n", chunkType, count)
	}
}

// demonstrateChunkingStrategies æ¼”ç¤ºåˆ†å—ç­–ç•¥
func demonstrateChunkingStrategies(markdown string) {
	fmt.Println("\n=== 2. åˆ†å—ç­–ç•¥æ¼”ç¤º ===")

	strategies := []struct {
		name   string
		config *mc.StrategyConfig
		desc   string
	}{
		{"å…ƒç´ çº§ç­–ç•¥", mc.ElementLevelConfig(), "é€ä¸ªå…ƒç´ åˆ†å—ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰"},
		{"å±‚çº§ç­–ç•¥(æ·±åº¦2)", mc.HierarchicalConfig(2), "æŒ‰æ ‡é¢˜å±‚çº§åˆ†ç»„å†…å®¹"},
		{"å±‚çº§ç­–ç•¥(æ·±åº¦3)", mc.HierarchicalConfig(3), "æ›´æ·±å±‚çº§çš„å†…å®¹åˆ†ç»„"},
		{"æ–‡æ¡£çº§ç­–ç•¥", mc.DocumentLevelConfig(), "æ•´ä¸ªæ–‡æ¡£ä½œä¸ºå•ä¸ªå—"},
	}

	fmt.Printf("æµ‹è¯•æ–‡æ¡£å¤§å°: %d å­—èŠ‚\n\n", len(markdown))

	for i, strategy := range strategies {
		fmt.Printf("%d. %s - %s\n", i+1, strategy.name, strategy.desc)

		config := mc.DefaultConfig()
		config.ChunkingStrategy = strategy.config

		chunker := mc.NewMarkdownChunkerWithConfig(config)
		start := time.Now()
		chunks, err := chunker.ChunkDocument([]byte(markdown))
		duration := time.Since(start)

		if err != nil {
			fmt.Printf("   é”™è¯¯: %v\n\n", err)
			continue
		}

		stats := chunker.GetPerformanceStats()
		fmt.Printf("   å—æ•°é‡: %d\n", len(chunks))
		fmt.Printf("   å¤„ç†æ—¶é—´: %v\n", duration)
		fmt.Printf("   å†…å­˜ä½¿ç”¨: %d KB\n", stats.MemoryUsed/1024)

		// æ˜¾ç¤ºå‰å‡ ä¸ªå—çš„ä¿¡æ¯
		fmt.Printf("   å‰3ä¸ªå—:\n")
		for j, chunk := range chunks[:min(3, len(chunks))] {
			preview := strings.ReplaceAll(chunk.Text, "\n", " ")
			if len(preview) > 60 {
				preview = preview[:60] + "..."
			}
			fmt.Printf("     %d. %s (Level %d): %s\n", j+1, chunk.Type, chunk.Level, preview)
		}
		if len(chunks) > 3 {
			fmt.Printf("     ... è¿˜æœ‰ %d ä¸ªå—\n", len(chunks)-3)
		}
		fmt.Println()
	}

	// æ¼”ç¤ºåŠ¨æ€ç­–ç•¥åˆ‡æ¢
	fmt.Println("åŠ¨æ€ç­–ç•¥åˆ‡æ¢æ¼”ç¤º:")
	chunker := mc.NewMarkdownChunker()

	// å¼€å§‹ä½¿ç”¨å…ƒç´ çº§ç­–ç•¥
	chunks1, _ := chunker.ChunkDocument([]byte(markdown))
	fmt.Printf("  å…ƒç´ çº§ç­–ç•¥: %d å—\n", len(chunks1))

	// åˆ‡æ¢åˆ°å±‚çº§ç­–ç•¥
	chunker.SetStrategy("hierarchical", mc.HierarchicalConfig(2))
	chunks2, _ := chunker.ChunkDocument([]byte(markdown))
	fmt.Printf("  å±‚çº§ç­–ç•¥: %d å—\n", len(chunks2))

	// åˆ‡æ¢åˆ°æ–‡æ¡£çº§ç­–ç•¥
	chunker.SetStrategy("document-level", mc.DocumentLevelConfig())
	chunks3, _ := chunker.ChunkDocument([]byte(markdown))
	fmt.Printf("  æ–‡æ¡£çº§ç­–ç•¥: %d å—\n", len(chunks3))
}

// demonstrateAdvancedFeatures æ¼”ç¤ºé«˜çº§åŠŸèƒ½
func demonstrateAdvancedFeatures(markdown string) {
	fmt.Println("\n=== 2. é«˜çº§åŠŸèƒ½æ¼”ç¤º ===")

	config := mc.DefaultConfig()
	config.CustomExtractors = []mc.MetadataExtractor{
		&mc.LinkExtractor{},
		&mc.ImageExtractor{},
		&mc.CodeComplexityExtractor{},
	}
	config.FilterEmptyChunks = true
	config.MaxChunkSize = 2000

	chunker := mc.NewMarkdownChunkerWithConfig(config)
	chunks, err := chunker.ChunkDocument([]byte(markdown))
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("é«˜çº§åŠŸèƒ½ç»“æœ:\n")
	fmt.Printf("  å¤„ç†å—æ•°: %d\n", len(chunks))

	// ç»Ÿè®¡é“¾æ¥å’Œå›¾ç‰‡
	totalLinks := 0
	totalImages := 0
	for _, chunk := range chunks {
		totalLinks += len(chunk.Links)
		totalImages += len(chunk.Images)
	}

	fmt.Printf("  æå–çš„é“¾æ¥æ€»æ•°: %d\n", totalLinks)
	fmt.Printf("  æå–çš„å›¾ç‰‡æ€»æ•°: %d\n", totalImages)

	// æ˜¾ç¤ºå‰å‡ ä¸ªå—çš„è¯¦ç»†ä¿¡æ¯
	fmt.Printf("  å‰3ä¸ªå—çš„è¯¦ç»†ä¿¡æ¯:\n")
	for i, chunk := range chunks {
		if i >= 3 {
			break
		}

		fmt.Printf("    å— %d (%s):\n", i+1, chunk.Type)
		fmt.Printf("      ä½ç½®: %d:%d-%d:%d\n",
			chunk.Position.StartLine, chunk.Position.StartCol,
			chunk.Position.EndLine, chunk.Position.EndCol)
		fmt.Printf("      å†…å®¹é•¿åº¦: %d\n", len(chunk.Content))
		fmt.Printf("      å“ˆå¸Œ: %s...\n", chunk.Hash[:16])

		if len(chunk.Links) > 0 {
			fmt.Printf("      é“¾æ¥:\n")
			for _, link := range chunk.Links {
				fmt.Printf("        - %s (%s): %s\n", link.Text, link.Type, link.URL)
			}
		}

		if len(chunk.Images) > 0 {
			fmt.Printf("      å›¾ç‰‡:\n")
			for _, img := range chunk.Images {
				fmt.Printf("        - %s: %s\n", img.Alt, img.URL)
			}
		}
	}
}

// demonstrateErrorHandlingAndRecovery æ¼”ç¤ºé”™è¯¯å¤„ç†å’Œæ¢å¤
func demonstrateErrorHandlingAndRecovery(markdown string) {
	fmt.Println("\n=== 3. é”™è¯¯å¤„ç†å’Œæ¢å¤æ¼”ç¤º ===")

	// åˆ›å»ºä¼šäº§ç”Ÿé”™è¯¯çš„é…ç½®
	config := mc.DefaultConfig()
	config.MaxChunkSize = 200 // è¾ƒå°çš„é™åˆ¶
	config.ErrorHandling = mc.ErrorModePermissive

	chunker := mc.NewMarkdownChunkerWithConfig(config)
	chunks, err := chunker.ChunkDocument([]byte(markdown))

	fmt.Printf("é”™è¯¯å¤„ç†ç»“æœ:\n")
	fmt.Printf("  è¿”å›é”™è¯¯: %v\n", err)
	fmt.Printf("  æˆåŠŸå¤„ç†å—æ•°: %d\n", len(chunks))
	fmt.Printf("  è®°å½•çš„é”™è¯¯æ•°: %d\n", len(chunker.GetErrors()))

	if chunker.HasErrors() {
		// æŒ‰ç±»å‹ç»Ÿè®¡é”™è¯¯
		errorTypeCount := make(map[mc.ErrorType]int)
		for _, err := range chunker.GetErrors() {
			errorTypeCount[err.Type]++
		}

		fmt.Printf("  é”™è¯¯ç±»å‹åˆ†å¸ƒ:\n")
		for errorType, count := range errorTypeCount {
			fmt.Printf("    %s: %d\n", errorType.String(), count)
		}

		// æ˜¾ç¤ºå‰å‡ ä¸ªé”™è¯¯çš„è¯¦ç»†ä¿¡æ¯
		fmt.Printf("  å‰3ä¸ªé”™è¯¯è¯¦æƒ…:\n")
		for i, err := range chunker.GetErrors() {
			if i >= 3 {
				break
			}
			fmt.Printf("    é”™è¯¯ %d: %s - %s\n", i+1, err.Type.String(), err.Message)
			if len(err.Context) > 0 {
				fmt.Printf("      ä¸Šä¸‹æ–‡: %+v\n", err.Context)
			}
		}
	}
}

// demonstratePerformanceMonitoring æ¼”ç¤ºæ€§èƒ½ç›‘æ§
func demonstratePerformanceMonitoring(markdown string) {
	fmt.Println("\n=== 4. æ€§èƒ½ç›‘æ§æ¼”ç¤º ===")

	config := mc.DefaultConfig()
	config.PerformanceMode = mc.PerformanceModeSpeedOptimized
	config.EnableObjectPooling = true

	chunker := mc.NewMarkdownChunkerWithConfig(config)

	// å¤šæ¬¡å¤„ç†ä»¥è·å¾—æ›´å‡†ç¡®çš„æ€§èƒ½æ•°æ®
	var totalChunks int
	iterations := 3

	start := time.Now()
	for i := 0; i < iterations; i++ {
		chunks, err := chunker.ChunkDocument([]byte(markdown))
		if err != nil {
			log.Printf("å¤„ç†é”™è¯¯: %v", err)
			continue
		}
		totalChunks += len(chunks)
		chunker.ResetPerformanceMonitor()
	}
	totalTime := time.Since(start)

	// æœ€åä¸€æ¬¡å¤„ç†è·å–è¯¦ç»†ç»Ÿè®¡
	chunks, _ := chunker.ChunkDocument([]byte(markdown))
	stats := chunker.GetPerformanceStats()

	fmt.Printf("æ€§èƒ½ç›‘æ§ç»“æœ (%dæ¬¡å¤„ç†):\n", iterations)
	fmt.Printf("  æ€»å¤„ç†æ—¶é—´: %v\n", totalTime)
	fmt.Printf("  å¹³å‡æ¯æ¬¡æ—¶é—´: %v\n", totalTime/time.Duration(iterations))
	fmt.Printf("  æœ€åä¸€æ¬¡ç»Ÿè®¡:\n")
	fmt.Printf("    å¤„ç†æ—¶é—´: %v\n", stats.ProcessingTime)
	fmt.Printf("    å†…å­˜ä½¿ç”¨: %d KB\n", stats.MemoryUsed/1024)
	fmt.Printf("    å³°å€¼å†…å­˜: %d KB\n", stats.PeakMemory/1024)
	fmt.Printf("    å¤„ç†é€Ÿåº¦: %.2f å—/ç§’\n", stats.ChunksPerSecond)
	fmt.Printf("    å­—èŠ‚å¤„ç†é€Ÿåº¦: %.2f KB/ç§’\n", stats.BytesPerSecond/1024)
	fmt.Printf("    æ€»å—æ•°: %d\n", stats.TotalChunks)
	fmt.Printf("    å—å†…å®¹æ€»å¤§å°: %d å­—èŠ‚\n", stats.ChunkBytes)

	fmt.Printf("  å¹³å‡æ¯å—å¤§å°: %.2f å­—èŠ‚\n", float64(stats.ChunkBytes)/float64(len(chunks)))
}

// demonstrateLoggingFeatures æ¼”ç¤ºæ—¥å¿—åŠŸèƒ½
func demonstrateLoggingFeatures(markdown string) {
	fmt.Println("\n=== 5. æ—¥å¿—åŠŸèƒ½æ¼”ç¤º ===")

	// æ¼”ç¤ºä¸åŒæ—¥å¿—çº§åˆ«
	logLevels := []string{"ERROR", "WARN", "INFO", "DEBUG"}

	for _, level := range logLevels {
		fmt.Printf("æµ‹è¯•æ—¥å¿—çº§åˆ«: %s\n", level)

		config := mc.DefaultConfig()
		config.EnableLog = true
		config.LogLevel = level
		config.LogFormat = "console"
		config.LogDirectory = fmt.Sprintf("./demo-logs/%s", strings.ToLower(level))

		// ä¸ºäº†æ¼”ç¤ºé”™è¯¯æ—¥å¿—ï¼Œåœ¨æŸäº›çº§åˆ«è®¾ç½®å°çš„å—å¤§å°é™åˆ¶
		if level == "ERROR" || level == "WARN" {
			config.MaxChunkSize = 200
			config.ErrorHandling = mc.ErrorModePermissive
		}

		chunker := mc.NewMarkdownChunkerWithConfig(config)
		start := time.Now()
		chunks, err := chunker.ChunkDocument([]byte(markdown))
		processingTime := time.Since(start)

		fmt.Printf("  å¤„ç†ç»“æœ: %d ä¸ªå—\n", len(chunks))
		fmt.Printf("  å¤„ç†æ—¶é—´: %v\n", processingTime)
		fmt.Printf("  è¿”å›é”™è¯¯: %v\n", err)

		if chunker.HasErrors() {
			fmt.Printf("  è®°å½•çš„é”™è¯¯: %d\n", len(chunker.GetErrors()))
		}

		fmt.Printf("  æ—¥å¿—ç›®å½•: %s\n", config.LogDirectory)
		fmt.Println()
	}

	// æ¼”ç¤ºJSONæ ¼å¼æ—¥å¿—
	fmt.Println("JSONæ ¼å¼æ—¥å¿—æ¼”ç¤º:")
	config := mc.DefaultConfig()
	config.EnableLog = true
	config.LogLevel = "INFO"
	config.LogFormat = "json"
	config.LogDirectory = "./demo-logs/json"
	config.CustomExtractors = []mc.MetadataExtractor{
		&mc.LinkExtractor{},
		&mc.ImageExtractor{},
		&mc.CodeComplexityExtractor{},
	}

	chunker := mc.NewMarkdownChunkerWithConfig(config)
	chunks, err := chunker.ChunkDocument([]byte(markdown))

	fmt.Printf("  JSONæ ¼å¼å¤„ç†ç»“æœ: %d ä¸ªå—\n", len(chunks))
	fmt.Printf("  è¿”å›é”™è¯¯: %v\n", err)
	fmt.Printf("  æ—¥å¿—ç›®å½•: %s\n", config.LogDirectory)
	fmt.Println("  JSONæ ¼å¼ä¾¿äºæ—¥å¿—èšåˆå’Œåˆ†æ")

	// æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡ï¼ˆä¹Ÿä¼šè¢«è®°å½•åˆ°æ—¥å¿—ä¸­ï¼‰
	stats := chunker.GetPerformanceStats()
	fmt.Printf("  æ€§èƒ½ç»Ÿè®¡ï¼ˆå·²è®°å½•åˆ°æ—¥å¿—ï¼‰:\n")
	fmt.Printf("    å¤„ç†æ—¶é—´: %v\n", stats.ProcessingTime)
	fmt.Printf("    å†…å­˜ä½¿ç”¨: %d KB\n", stats.MemoryUsed/1024)
	fmt.Printf("    å¤„ç†é€Ÿåº¦: %.2f å—/ç§’\n", stats.ChunksPerSecond)
}

// demonstrateMetadataExtraction æ¼”ç¤ºå…ƒæ•°æ®æå–
func demonstrateMetadataExtraction(markdown string) {
	fmt.Println("\n=== 5. å…ƒæ•°æ®æå–æ¼”ç¤º ===")

	config := mc.DefaultConfig()
	config.CustomExtractors = []mc.MetadataExtractor{
		&mc.LinkExtractor{},
		&mc.ImageExtractor{},
		&mc.CodeComplexityExtractor{},
	}

	chunker := mc.NewMarkdownChunkerWithConfig(config)
	chunks, err := chunker.ChunkDocument([]byte(markdown))
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("å…ƒæ•°æ®æå–ç»“æœ:\n")

	// åˆ†æä»£ç å—çš„å¤æ‚åº¦
	fmt.Printf("  ä»£ç å¤æ‚åº¦åˆ†æ:\n")
	for _, chunk := range chunks {
		if chunk.Type == "code" {
			if complexity, exists := chunk.Metadata["code_complexity"]; exists {
				language := chunk.Metadata["language"]
				fmt.Printf("    %s ä»£ç å—å¤æ‚åº¦: %s\n", language, complexity)

				if funcCount, exists := chunk.Metadata["function_count"]; exists {
					fmt.Printf("      å‡½æ•°æ•°é‡: %s\n", funcCount)
				}
				if loopCount, exists := chunk.Metadata["loop_count"]; exists {
					fmt.Printf("      å¾ªç¯æ•°é‡: %s\n", loopCount)
				}
				if condCount, exists := chunk.Metadata["conditional_count"]; exists {
					fmt.Printf("      æ¡ä»¶è¯­å¥æ•°é‡: %s\n", condCount)
				}
			}
		}
	}

	// åˆ†æé“¾æ¥åˆ†å¸ƒ
	fmt.Printf("  é“¾æ¥åˆ†å¸ƒåˆ†æ:\n")
	linkTypes := make(map[string]int)
	for _, chunk := range chunks {
		for _, link := range chunk.Links {
			linkTypes[link.Type]++
		}
	}
	for linkType, count := range linkTypes {
		fmt.Printf("    %s é“¾æ¥: %d ä¸ª\n", linkType, count)
	}

	// åˆ†æå›¾ç‰‡ç±»å‹
	fmt.Printf("  å›¾ç‰‡ç±»å‹åˆ†æ:\n")
	imageExts := make(map[string]int)
	for _, chunk := range chunks {
		for _, img := range chunk.Images {
			// ä»URLä¸­æå–æ‰©å±•å
			parts := strings.Split(img.URL, ".")
			if len(parts) > 1 {
				ext := strings.ToLower(parts[len(parts)-1])
				imageExts[ext]++
			}
		}
	}
	for ext, count := range imageExts {
		fmt.Printf("    .%s å›¾ç‰‡: %d ä¸ª\n", ext, count)
	}
}

// demonstrateContentAnalysis æ¼”ç¤ºå†…å®¹åˆ†æ
func demonstrateContentAnalysis(markdown string) {
	fmt.Println("\n=== 7. å†…å®¹åˆ†ææ¼”ç¤º ===")

	chunker := mc.NewMarkdownChunker()
	chunks, err := chunker.ChunkDocument([]byte(markdown))
	if err != nil {
		log.Fatal(err)
	}

	// åˆ†ææ–‡æ¡£ç»“æ„
	fmt.Printf("æ–‡æ¡£ç»“æ„åˆ†æ:\n")

	// æ ‡é¢˜å±‚æ¬¡åˆ†æ
	headingLevels := make(map[int]int)
	for _, chunk := range chunks {
		if chunk.Type == "heading" {
			headingLevels[chunk.Level]++
		}
	}

	fmt.Printf("  æ ‡é¢˜å±‚æ¬¡åˆ†å¸ƒ:\n")
	for level := 1; level <= 6; level++ {
		if count, exists := headingLevels[level]; exists {
			fmt.Printf("    H%d: %d ä¸ª\n", level, count)
		}
	}

	// å†…å®¹é•¿åº¦åˆ†æ
	fmt.Printf("  å†…å®¹é•¿åº¦åˆ†æ:\n")
	var totalContentLength, totalTextLength int
	var minLength, maxLength int = 999999, 0

	for _, chunk := range chunks {
		contentLen := len(chunk.Content)
		textLen := len(chunk.Text)

		totalContentLength += contentLen
		totalTextLength += textLen

		if contentLen < minLength {
			minLength = contentLen
		}
		if contentLen > maxLength {
			maxLength = contentLen
		}
	}

	fmt.Printf("    å¹³å‡å†…å®¹é•¿åº¦: %.2f å­—ç¬¦\n", float64(totalContentLength)/float64(len(chunks)))
	fmt.Printf("    å¹³å‡æ–‡æœ¬é•¿åº¦: %.2f å­—ç¬¦\n", float64(totalTextLength)/float64(len(chunks)))
	fmt.Printf("    æœ€çŸ­å—: %d å­—ç¬¦\n", minLength)
	fmt.Printf("    æœ€é•¿å—: %d å­—ç¬¦\n", maxLength)

	// ç”Ÿæˆå†…å®¹æ‘˜è¦JSONï¼ˆå‰5ä¸ªå—ï¼‰
	fmt.Printf("  å†…å®¹æ‘˜è¦ (å‰5ä¸ªå—):\n")
	summary := make([]map[string]interface{}, 0)
	for i, chunk := range chunks {
		if i >= 5 {
			break
		}

		chunkSummary := map[string]interface{}{
			"id":           chunk.ID,
			"type":         chunk.Type,
			"level":        chunk.Level,
			"content_size": len(chunk.Content),
			"text_size":    len(chunk.Text),
			"position": map[string]int{
				"start_line": chunk.Position.StartLine,
				"end_line":   chunk.Position.EndLine,
			},
			"hash":         chunk.Hash[:16],
			"links_count":  len(chunk.Links),
			"images_count": len(chunk.Images),
		}

		// æ·»åŠ å…³é”®å…ƒæ•°æ®
		if chunk.Type == "heading" {
			chunkSummary["heading_level"] = chunk.Metadata["heading_level"]
		} else if chunk.Type == "code" {
			chunkSummary["language"] = chunk.Metadata["language"]
			chunkSummary["line_count"] = chunk.Metadata["line_count"]
		} else if chunk.Type == "table" {
			chunkSummary["rows"] = chunk.Metadata["rows"]
			chunkSummary["columns"] = chunk.Metadata["columns"]
		}

		summary = append(summary, chunkSummary)
	}

	jsonData, _ := json.MarshalIndent(summary, "    ", "  ")
	fmt.Printf("    %s\n", string(jsonData))
}

// Helper functions
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}
